{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('nlp-getting-started/train.csv')\n",
    "test = pd.read_csv('nlp-getting-started/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'TextPreprocessor': {\n",
    "        'mode_remove_stops': True,\n",
    "        'mode_drop_long_words': True,\n",
    "        'max_size_vocab': 50000,\n",
    "        'max_doc_freq': 0.9,\n",
    "        'min_count': 5,\n",
    "        'pad_word': '<PAD>', \n",
    "        'text_column': 'text'\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_expression_map = {\n",
    "    'url': 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\n",
    "    'mention': r'(?<=@)\\w+',\n",
    "    'hashtag': '(?<=#)\\w+'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(object):\n",
    "    def __init__(self, config):\n",
    "        \"\"\"Preparing text features.\"\"\"\n",
    "\n",
    "        self._mode_remove_stops = config.get('mode_remove_stops', True)\n",
    "        self._pad_word = config.get('pad_word', '<PAD>')\n",
    "        self._text_column = config.get('text_column')\n",
    "\n",
    "    def _clean_text(self, input_text):\n",
    "        \"\"\"Delete special symbols.\"\"\"\n",
    "\n",
    "        input_text = input_text.str.lower()\n",
    "        input_text = input_text.str.replace(r'[^a-z ]+', ' ') \n",
    "        input_text = input_text.str.replace(r' +', ' ')\n",
    "        input_text = input_text.str.replace(r'^ ', '')\n",
    "        input_text = input_text.str.replace(r' $', '')\n",
    "\n",
    "        return input_text\n",
    "    \n",
    "    def _remove_stop_words(self, input_sentence):\n",
    "        stop_words = set(stopwords.words('english')) \n",
    "        word_tokens = word_tokenize(input_sentence) \n",
    "        \n",
    "        return ' '.join(list(filter(lambda word: word not in stop_words, word_tokens)))\n",
    "\n",
    "    def _find_url(self, input_sequence, regular_expression): \n",
    "        text = re.findall(regular_expression,\n",
    "                          input_sequence)\n",
    "        \n",
    "        url =  \"\".join(text)\n",
    "        return 0 if url == '' else 1\n",
    "    \n",
    "    def _remove_url(self, input_sequence, regular_expression):\n",
    "\n",
    "        return re.sub(regular_expression,\n",
    "                      '',\n",
    "                      input_sequence)\n",
    "\n",
    "    def transform(self, df):\n",
    "        \n",
    "        # check if the text has url, mention or hashtag\n",
    "        df['has_url'] = df[self._text_column].apply(\n",
    "            lambda x: self._find_url(x, regular_expression_map['url'])\n",
    "        )\n",
    "        df['has_mention'] = df[self._text_column].apply(\n",
    "            lambda x: self._find_url(x, regular_expression_map['mention'])\n",
    "        )\n",
    "        df['has_hashtag'] = df[self._text_column].apply(\n",
    "            lambda x: self._find_url(x, regular_expression_map['hashtag'])\n",
    "        )\n",
    "        \n",
    "        # get some counts\n",
    "        df['text_len'] = df['text'].astype(str).apply(len)\n",
    "        df['text_counter'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "        \n",
    "        # df[self._text_column] = self._clean_text(df[self._text_column])\n",
    "        \n",
    "        # clean text\n",
    "        df[self._text_column] = df[self._text_column].apply(\n",
    "            lambda x: self._remove_url(x, regular_expression_map['url'])\n",
    "        )\n",
    "        df[self._text_column] = df[self._text_column].apply(\n",
    "            lambda x: self._remove_url(x, regular_expression_map['mention'])\n",
    "        )\n",
    "        df[self._text_column] = df[self._text_column].apply(\n",
    "            lambda x: self._remove_url(x, regular_expression_map['hashtag'])\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # remove stop words\n",
    "        if self._mode_remove_stops:\n",
    "            df[self._text_column] = df[self._text_column].apply(self._remove_stop_words, 1)\n",
    "        \n",
    "        \n",
    "        return df\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = TextPreprocessor(config['TextPreprocessor']).transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_mention</th>\n",
       "      <th>has_hashtag</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds Reason # May ALLAH Forgive us</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask . Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked 'shelter place ' notified ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive # evacuation orders Cali...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent photo Ruby # smoke # pours school</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN            Our Deeds Reason # May ALLAH Forgive us   \n",
       "1   4     NaN      NaN            Forest fire near La Ronge Sask . Canada   \n",
       "2   5     NaN      NaN  All residents asked 'shelter place ' notified ...   \n",
       "3   6     NaN      NaN  13,000 people receive # evacuation orders Cali...   \n",
       "4   7     NaN      NaN    Just got sent photo Ruby # smoke # pours school   \n",
       "\n",
       "   target  has_url  has_mention  has_hashtag  text_len  text_counter  \n",
       "0       1        0            0            1        69            13  \n",
       "1       1        0            0            0        38             7  \n",
       "2       1        0            0            0       133            22  \n",
       "3       1        0            0            1        65             8  \n",
       "4       1        0            0            1        88            16  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
